{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.impute import KNNImputer\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from feature_selection import write_features_to_csv, get_features_from_model\n",
    "from preprocessing import subsets, write_ahi_to_csv, generate_subset_dataset\n",
    "from modeling import split_data, train_model, find_best_data\n",
    "from threshold_logs import extract_info_folder, extract_log\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Sleep Heart Health Study Dataset\n",
    "shhs1 = pd.read_csv(\n",
    "    \"../../data/raw/shhs1-dataset-0.20.0.csv\", encoding=\"cp1252\", engine=\"python\"\n",
    ")\n",
    "# read Sleep Heart Health Study Dictionary\n",
    "var_dict = pd.read_csv(\n",
    "    \"../../data/interim/shhs-data-dictionary-0.20.0-variables.csv\",\n",
    "    encoding=\"cp1252\",\n",
    "    engine=\"python\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove sleep monitoring columns from independent variables (unattinable for predicting)\n",
    "sleep_monitoring_col = var_dict[\n",
    "    var_dict[\"folder\"].str.contains(r\"sleep monitoring\", case=False, na=False)\n",
    "][\"id\"]\n",
    "# drop target variables, pptidr (has numerical and categorical values in one column), and sleep monitoring columns in independent variable\n",
    "x = shhs1.copy().drop(columns=[\"ahi_c0h4a\", \"pptidr\"])\n",
    "for col in sleep_monitoring_col:\n",
    "    if col in x.columns:\n",
    "        x = x.drop(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize x\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)  # You can change the number of neighbors if needed\n",
    "x_imputed_scaled = imputer.fit_transform(x_scaled)\n",
    "\n",
    "# reverse scaling\n",
    "x_imputed = scaler.inverse_transform(x_imputed_scaled)\n",
    "\n",
    "# Convert the result back to DataFrame\n",
    "x_imputed = pd.DataFrame(x_imputed, columns=x.columns)\n",
    "\n",
    "# save target hf15 col\n",
    "hf15 = x_imputed[\"hf15\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection to diagnose CSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS DICT UNLESS YOU ARE ADDING ANOTHER EXISTING FS METHOD. change selected methods if trying to test a subset of methods\n",
    "all_methods = {\n",
    "    \"ahi_c0h4a\": [\n",
    "        \"decision tree\",\n",
    "        \"random forest\",\n",
    "        \"mutual information\",\n",
    "        \"forward selection AIC\",\n",
    "        \"forward selection BIC\",\n",
    "        \"backward selection AIC\",\n",
    "    ],\n",
    "    \"hf15\": [\n",
    "        \"MRMR 10\",\n",
    "        \"MRMR 20\",\n",
    "        \"random forest\",\n",
    "        \"decision tree\",\n",
    "        \"mutual information\",\n",
    "        \"forward selection AIC\",\n",
    "        \"forward selection BIC\",\n",
    "        \"backward selection AIC\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select from all_methods\n",
    "selected_methods = {\"ahi_c0h4a\": all_methods[\"ahi_c0h4a\"], \"hf15\": all_methods[\"hf15\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target variable:  ahi_c0h4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning decision tree on target ahi_c0h4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:04,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using decision tree on ahi_c0h4a:             254\n",
      "Beginning random forest on target ahi_c0h4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:30<01:10, 17.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using random forest on ahi_c0h4a:             279\n",
      "Beginning mutual information on target ahi_c0h4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:34<00:34, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using mutual information on ahi_c0h4a:             193\n",
      "Beginning forward selection AIC on target ahi_c0h4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [01:09<00:41, 20.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using forward selection AIC on ahi_c0h4a:             26\n",
      "Beginning forward selection BIC on target ahi_c0h4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:16<00:15, 15.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using forward selection BIC on ahi_c0h4a:             9\n",
      "Beginning backward selection AIC on target ahi_c0h4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [56:22<00:00, 563.68s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using backward selection AIC on ahi_c0h4a:             229\n",
      "\n",
      "\n",
      "\n",
      "target variable:  hf15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning MRMR 10 on target hf15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.81it/s]\n",
      " 12%|█▎        | 1/8 [00:03<00:26,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using MRMR 10 on hf15:             10\n",
      "Beginning MRMR 20 on target hf15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  6.41it/s]\n",
      " 25%|██▌       | 2/8 [00:07<00:21,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using MRMR 20 on hf15:             20\n",
      "Beginning random forest on target hf15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:27<00:56, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using random forest on hf15:             262\n",
      "Beginning decision tree on target hf15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:28<00:28,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using decision tree on hf15:             94\n",
      "Beginning mutual information on target hf15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:32<00:18,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using mutual information on hf15:             159\n",
      "Beginning forward selection AIC on target hf15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [01:06<00:31, 15.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using forward selection AIC on hf15:             24\n",
      "Beginning forward selection BIC on target hf15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [01:22<00:15, 15.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using forward selection BIC on hf15:             13\n",
      "Beginning backward selection AIC on target hf15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [1:00:51<00:00, 456.48s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features selected using backward selection AIC on hf15:             215\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# !!!: This block of code on all the feature selection methods (specifically backward selection) will take around 2 hours.\n",
    "filepath = \"../../data/interim/feature_selection/\"\n",
    "\n",
    "# reset x_imputed if hf15 is removed in for loop\n",
    "x_imputed[\"hf15\"] = hf15\n",
    "\n",
    "# iterate through chosen methods (out of the available methods) and write important features to a CSV file\n",
    "for target in [\"ahi_c0h4a\", \"hf15\"]:\n",
    "    y = shhs1[target]\n",
    "    targets = [target]\n",
    "\n",
    "    if target == \"hf15\":\n",
    "        y = hf15\n",
    "        x_imputed = x_imputed.drop(columns=[\"hf15\"])\n",
    "\n",
    "        # if target is heart failure, add nsrrid for preprocessing\n",
    "        targets.append(\"nsrrid\")\n",
    "\n",
    "    print(\"target variable: \", target)\n",
    "    for method in tqdm(selected_methods[target]):\n",
    "        print(f\"Beginning {method} on target {target}\")\n",
    "        # runs feature selection using the method given and returns either the importances or features (depending on the model)\n",
    "        model_importances, model_features = get_features_from_model(\n",
    "            method, x_imputed, y\n",
    "        )\n",
    "\n",
    "        # creates a new DataFrame using the important features from the model and writes the new DF to a CSV file in the given file path\n",
    "        print(\n",
    "            f\"# features selected using {method} on {target}: \\\n",
    "            {write_features_to_csv(x_imputed, shhs1, method, targets, filepath, model_importances, model_features)}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cheap feature subset to diagnose CSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../data/processed/cheap_features\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheap_features = [\n",
    "    \"Anthropometry\",\n",
    "    \"Clinical Data\",\n",
    "    \"Demographics\",\n",
    "    \"General Health\",\n",
    "    \"Lifestyle and Behavioral Health\",\n",
    "    \"Medical History\",\n",
    "    \"Sleep Treatment\",\n",
    "]\n",
    "abbreviations = {\n",
    "    \"Anthropometry\": \"Ant\",\n",
    "    \"Clinical Data\": \"Cli\",\n",
    "    \"Demographics\": \"Dem\",\n",
    "    \"General Health\": \"Gen\",\n",
    "    \"Lifestyle and Behavioral Health\": \"Lif\",\n",
    "    \"Medical History\": \"Med\",\n",
    "    \"Sleep Treatment\": \"Tre\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make subsets of cheap_features\n",
    "subsets = subsets(cheap_features)\n",
    "subsets = [list(subset) for subset in subsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cahi = shhs1[[\"nsrrid\", \"ahi_c0h4\"]]\n",
    "filepath = \"../../data/processed/cheap_features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of datasets with the given features\n",
    "datasets = []\n",
    "for subset in subsets:\n",
    "    generate_subset_dataset(var_dict, subset, shhs1, cahi, abbreviations, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate different threshold for CSA diagnose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_folder = \"../../data/interim/feature_selection/\"\n",
    "feature_selection_datasets = os.listdir(feature_selection_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "shhs1_4_var = shhs1[[\"nsrrid\", \"ahi_c0h4\", \"ahi_o0h4\", \"ahi_a0h4\"]]\n",
    "processed_filepath = \"../../data/processed/threshold/\"\n",
    "os.makedirs(processed_filepath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make different datasets with a dummy variable for each threshold\n",
    "for dataset in list(\n",
    "    filter(lambda dataset: \"hf15\" in dataset, feature_selection_datasets)\n",
    "):\n",
    "    hf = pd.read_csv(feature_selection_folder + dataset)\n",
    "\n",
    "    hf_ahi = pd.merge(hf, shhs1_4_var, on=\"nsrrid\", how=\"inner\")\n",
    "    hf_ahi = hf_ahi[hf_ahi[\"hf15\"] != 8]\n",
    "\n",
    "    # Calculates AHI given a range of thresholds and writes them to a CSV file\n",
    "    for threshold in range(1, 10):\n",
    "        for threshold_2 in range(1, 5):\n",
    "            write_ahi_to_csv(\n",
    "                hf_ahi.copy(), threshold, threshold_2, processed_filepath, dataset\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models: Finding cheap features subset to predict Central Sleep Apnea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../models/cheap_features/\", exist_ok=True)\n",
    "folder_loc = \"../../data/processed/cheap_features/\"\n",
    "datasets = os.listdir(\"../../data/processed/cheap_features/\")\n",
    "target = \"ahi_c0h4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [19:27<00:00,  9.20s/it]\n"
     ]
    }
   ],
   "source": [
    "best_mae, best_model, model_name, best_dataset, results = find_best_data(\n",
    "    folder_loc, datasets, target\n",
    ")\n",
    "\n",
    "pickle.dump(\n",
    "    best_model, open(\"../../models/cheap_features/\" + model_name + \".pkl\", \"wb\")\n",
    ")\n",
    "\n",
    "results = pd.read_csv(\"../../models/cheap_features/all_results.csv\")\n",
    "results[\"dataset\"] = [x.replace(\"[\", \"\").replace(\"]\", \"\") for x in results[\"dataset\"]]\n",
    "results.to_csv(\"../../models/cheap_features/\" + \"all_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge 4.684644069658723\n",
      "['gender' 'race' 'mstat' 'hip' 'neck20' 'coffee15' 'tea15' 'soda15'\n",
      " 'evsmok15' 'smknow15' 'asa15' 'age_s1' 'smokstat_s1' 'ethnicity' 'bmi_s1'\n",
      " 'educat' 'weight' 'waist' 'height' 'weight20' 'age_category_s1' 'nsrrid']\n"
     ]
    }
   ],
   "source": [
    "print(model_name, best_mae)\n",
    "print(best_model.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = pd.read_csv(\n",
    "    \"../../data/interim/shhs-data-dictionary-0.20.0-variables.csv\"\n",
    ")\n",
    "# keep only the rows where id == best_model.feature_names_in_\n",
    "features_dict = features_dict[features_dict[\"id\"].isin(best_model.feature_names_in_)]\n",
    "features_dict[[\"display_name\", \"description\", \"folder\"]].to_csv(\"./results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of the best cheap feature subset model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and model\n",
    "best_model = pickle.load(open(\"../../models/cheap_features/ridge.pkl\", \"rb\"))\n",
    "df = pd.read_csv(\"../../data/processed/cheap_features/Ant_Lif.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns.tolist()\n",
    "features.remove(target)\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/huailintang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.923385947687978, 'solver': 'sparse_cg'}\n",
      "-4.769159928697817\n",
      "Ridge(alpha=0.923385947687978, random_state=1, solver='sparse_cg')\n"
     ]
    }
   ],
   "source": [
    "# do RandomizedSearchCV to find best hyperparameters\n",
    "model = Ridge(random_state=1)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)\n",
    "\n",
    "param_grid = {\n",
    "    \"alpha\": uniform(0, 10),\n",
    "    \"solver\": [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    n_iter=20,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)\n",
    "print(search.best_estimator_)\n",
    "best_param = search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7100483689134505\n",
      "4.666369518021431\n"
     ]
    }
   ],
   "source": [
    "# test on validation set\n",
    "model = Ridge(**best_param, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, model.predict(X_test))\n",
    "print(mae)\n",
    "print(mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.86010832 -4.89426704 -4.76167671 -4.74352476 -4.58622282]\n",
      "-4.769159928697817\n"
     ]
    }
   ],
   "source": [
    "# cross validation training\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = Ridge(alpha=best_param[\"alpha\"], solver=best_param[\"solver\"], random_state=1)\n",
    "scores = cross_val_score(\n",
    "    model, X_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models: Finding feature selection to predict Central Sleep Apnea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = os.listdir(\"../../data/interim/feature_selection\")\n",
    "datasets = [dataset for dataset in datasets if \"ahi_c0h4a\" in dataset]\n",
    "\n",
    "folder_loc = \"../../data/interim/feature_selection/\"\n",
    "target = \"ahi_c0h4a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:37<00:00, 16.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "best_mae, best_model, model_name, best_dataset, detailed_results = find_best_data(\n",
    "    folder_loc, datasets, target\n",
    ")\n",
    "pickle.dump(\n",
    "    best_model,\n",
    "    open(\"../../models/cheap_features/\" + model_name + \"_feature_selection.pkl\", \"wb\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../../data/interim/feature_selection/{best_dataset}\")\n",
    "target = \"ahi_c0h4a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neck20', 'bmi_s1', 'age_s1', 'gender', 'diasbp', 'funres02', 'shhs1_tcvd', 'ess_s1', 'nonsp_st', 'hosnr02', 'benzod1', 'ccb1', 'nsrrid', 'shhs1_qc', 'twuweh02', 'race', 'estrgn1', 'waist', 'soda15', 'tea15', 'urdbpae', 'diuret1', 'pvdl1', 'height', 'weight', 'systbp']\n",
      "ridge 5.747435889334488\n"
     ]
    }
   ],
   "source": [
    "features = df.columns.tolist()\n",
    "features.remove(target)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)\n",
    "\n",
    "print(features)\n",
    "print(model_name, best_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folders = os.listdir(\"../../results/threshold/2023-11-13/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: feature_selection_mrmr20\n",
      "Model: decision_tree\n",
      "Target: hf15\n",
      "Threshold CAHI > 2\n",
      "Threshold CAHI > OAHI * 1/1\n"
     ]
    }
   ],
   "source": [
    "best_false_negative = 1000\n",
    "for folder in log_folders:\n",
    "    f1_test, f1_val, cm = extract_log(\n",
    "        \"../../results/threshold/2023-11-13/\" + folder + \"/find_threshold.log\"\n",
    "    )\n",
    "\n",
    "    if f1_test is None:\n",
    "        continue\n",
    "    # find the lowest false negative rate\n",
    "    false_negative = cm[0][1]\n",
    "    if false_negative < best_false_negative:\n",
    "        best_false_negative = false_negative\n",
    "        best_folder = folder\n",
    "        best_cm = cm\n",
    "        best_f1_test = f1_test\n",
    "        best_f1_val = f1_val\n",
    "\n",
    "extract_info_folder(best_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../models/cheap_features/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, features, target):\n",
    "    \"\"\"Split on test/train/val.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): input dataset\n",
    "        features (list): list of features\n",
    "        target (str): target column name\n",
    "    \"\"\"\n",
    "    # Split on test/train 80/20\n",
    "    # split startified on target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.3, random_state=1)\n",
    "    # make validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models: Finding cheap features to predict Central Sleep Apnea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_loc = '../data/processed/cheap_features/'\n",
    "datasets = os.listdir('../data/processed/cheap_features/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ahi_c0h4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_test, y_test, X_val, y_val):\n",
    "    \"\"\"Train model and return predictions.\n",
    "\n",
    "    Args:\n",
    "        model (sklearn model): model to train\n",
    "        X_train (pd.DataFrame): training data\n",
    "        y_train (pd.DataFrame): training labels\n",
    "        X_test (pd.DataFrame): test data\n",
    "        y_test (pd.DataFrame): test labels\n",
    "        X_val (pd.DataFrame): validation data\n",
    "        y_val (pd.DataFrame): validation labels\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    # Evaluaate\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    return mae, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [57:44<00:00, 27.28s/it] \n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "model_name = None\n",
    "best_mae = 100000\n",
    "best_dataset = None\n",
    "\n",
    "for dataset in tqdm(datasets):\n",
    "    # Load data\n",
    "    df = pd.read_csv(folder_loc + dataset)\n",
    "\n",
    "    features = df.columns.tolist()\n",
    "    features.remove(target)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)\n",
    "\n",
    "    # Train xgboost\n",
    "\n",
    "    mae_xgb, model_xgb = train_model(XGBRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train random forest\n",
    "\n",
    "    mae_rf, model_rf = train_model(RandomForestRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train linear regression\n",
    "\n",
    "    mae_lr, model_lr = train_model(LinearRegression(), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train lasso\n",
    "\n",
    "    mae_lasso, model_lasso = train_model(Lasso(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train ridge\n",
    "\n",
    "    mae_ridge, model_ridge = train_model(Ridge(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train decision tree\n",
    "\n",
    "    mae_dt, model_dt = train_model(DecisionTreeRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Save best model\n",
    "\n",
    "    if mae_xgb < best_mae:\n",
    "        best_mae = mae_xgb\n",
    "        best_model = model_xgb\n",
    "        model_name = 'xgb'\n",
    "        best_dataset = dataset\n",
    "    if mae_rf < best_mae:\n",
    "        best_mae = mae_rf\n",
    "        best_model = model_rf\n",
    "        model_name = 'rf'\n",
    "        best_dataset = dataset\n",
    "    if mae_lr < best_mae:\n",
    "        best_mae = mae_lr\n",
    "        best_model = model_lr\n",
    "        model_name = 'lr'\n",
    "        best_dataset = dataset\n",
    "    if mae_lasso < best_mae:\n",
    "        best_mae = mae_lasso\n",
    "        best_model = model_lasso\n",
    "        model_name = 'lasso'\n",
    "        best_dataset = dataset\n",
    "    if mae_ridge < best_mae:\n",
    "        best_mae = mae_ridge\n",
    "        best_model = model_ridge\n",
    "        model_name = 'ridge'\n",
    "        best_dataset = dataset\n",
    "    if mae_dt < best_mae:\n",
    "        best_mae = mae_dt\n",
    "        best_model = model_dt\n",
    "        model_name = 'dt'\n",
    "        best_dataset = dataset\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "pickle.dump(best_model, open('../models/cheap_features/' + model_name + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge 4.564480843250868\n"
     ]
    }
   ],
   "source": [
    "print(model_name, best_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hip', 'neck20', 'coffee15', 'tea15', 'soda15', 'evsmok15',\n",
       "       'smknow15', 'asa15', 'surgtr02', 'o2thpy02', 'smokstat_s1',\n",
       "       'bmi_s1', 'weight', 'waist', 'height', 'weight20', 'nsrrid'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antropometric features and Lifestyle and Behavioural features are the most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparemeter tuning of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'scoring' parameter of RandomizedSearchCV must be a str among {'explained_variance', 'fowlkes_mallows_score', 'precision_macro', 'jaccard', 'f1', 'v_measure_score', 'neg_median_absolute_error', 'adjusted_mutual_info_score', 'roc_auc_ovo_weighted', 'matthews_corrcoef', 'mutual_info_score', 'average_precision', 'r2', 'recall_samples', 'neg_negative_likelihood_ratio', 'neg_brier_score', 'recall_weighted', 'top_k_accuracy', 'neg_mean_squared_error', 'normalized_mutual_info_score', 'neg_mean_absolute_percentage_error', 'positive_likelihood_ratio', 'neg_mean_absolute_error', 'jaccard_macro', 'f1_macro', 'completeness_score', 'rand_score', 'homogeneity_score', 'f1_micro', 'roc_auc_ovr_weighted', 'jaccard_weighted', 'f1_samples', 'precision_micro', 'jaccard_samples', 'f1_weighted', 'roc_auc_ovr', 'neg_root_mean_squared_error', 'jaccard_micro', 'adjusted_rand_score', 'neg_mean_poisson_deviance', 'precision_samples', 'accuracy', 'precision_weighted', 'recall_macro', 'recall', 'balanced_accuracy', 'max_error', 'precision', 'neg_mean_gamma_deviance', 'neg_mean_squared_log_error', 'roc_auc_ovo', 'recall_micro', 'neg_log_loss', 'roc_auc'}, a callable, an instance of 'list', an instance of 'tuple', an instance of 'dict' or None. Got 'mean_absolute_error' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32mg:\\Other computers\\My Computer\\Masters\\Rice\\Fall23\\DSCI 535\\BCM_CSA_F23\\notebooks\\4.0-modes.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Computer/Masters/Rice/Fall23/DSCI%20535/BCM_CSA_F23/notebooks/4.0-modes.ipynb#X54sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Computer/Masters/Rice/Fall23/DSCI%20535/BCM_CSA_F23/notebooks/4.0-modes.ipynb#X54sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m: uniform(\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Computer/Masters/Rice/Fall23/DSCI%20535/BCM_CSA_F23/notebooks/4.0-modes.ipynb#X54sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msolver\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msvd\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcholesky\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlsqr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msparse_cg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Computer/Masters/Rice/Fall23/DSCI%20535/BCM_CSA_F23/notebooks/4.0-modes.ipynb#X54sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Computer/Masters/Rice/Fall23/DSCI%20535/BCM_CSA_F23/notebooks/4.0-modes.ipynb#X54sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m search \u001b[39m=\u001b[39m RandomizedSearchCV(model, param_grid, n_iter\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_absolute_error\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Computer/Masters/Rice/Fall23/DSCI%20535/BCM_CSA_F23/notebooks/4.0-modes.ipynb#X54sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Computer/Masters/Rice/Fall23/DSCI%20535/BCM_CSA_F23/notebooks/4.0-modes.ipynb#X54sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(search\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Computer/Masters/Rice/Fall23/DSCI%20535/BCM_CSA_F23/notebooks/4.0-modes.ipynb#X54sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(search\u001b[39m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\Risto Trajanov\\anaconda3\\envs\\csa\\lib\\site-packages\\sklearn\\base.py:1144\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m partial_fit_and_fitted \u001b[39m=\u001b[39m (\n\u001b[0;32m   1140\u001b[0m     fit_method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpartial_fit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1141\u001b[0m )\n\u001b[0;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_skip_validation \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1144\u001b[0m     estimator\u001b[39m.\u001b[39;49m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[0;32m   1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Risto Trajanov\\anaconda3\\envs\\csa\\lib\\site-packages\\sklearn\\base.py:637\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    630\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \n\u001b[0;32m    632\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m     validate_parameter_constraints(\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parameter_constraints,\n\u001b[0;32m    639\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    640\u001b[0m         caller_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[0;32m    641\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Risto Trajanov\\anaconda3\\envs\\csa\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     96\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'scoring' parameter of RandomizedSearchCV must be a str among {'explained_variance', 'fowlkes_mallows_score', 'precision_macro', 'jaccard', 'f1', 'v_measure_score', 'neg_median_absolute_error', 'adjusted_mutual_info_score', 'roc_auc_ovo_weighted', 'matthews_corrcoef', 'mutual_info_score', 'average_precision', 'r2', 'recall_samples', 'neg_negative_likelihood_ratio', 'neg_brier_score', 'recall_weighted', 'top_k_accuracy', 'neg_mean_squared_error', 'normalized_mutual_info_score', 'neg_mean_absolute_percentage_error', 'positive_likelihood_ratio', 'neg_mean_absolute_error', 'jaccard_macro', 'f1_macro', 'completeness_score', 'rand_score', 'homogeneity_score', 'f1_micro', 'roc_auc_ovr_weighted', 'jaccard_weighted', 'f1_samples', 'precision_micro', 'jaccard_samples', 'f1_weighted', 'roc_auc_ovr', 'neg_root_mean_squared_error', 'jaccard_micro', 'adjusted_rand_score', 'neg_mean_poisson_deviance', 'precision_samples', 'accuracy', 'precision_weighted', 'recall_macro', 'recall', 'balanced_accuracy', 'max_error', 'precision', 'neg_mean_gamma_deviance', 'neg_mean_squared_log_error', 'roc_auc_ovo', 'recall_micro', 'neg_log_loss', 'roc_auc'}, a callable, an instance of 'list', an instance of 'tuple', an instance of 'dict' or None. Got 'mean_absolute_error' instead."
     ]
    }
   ],
   "source": [
    "# do RandomizedSearchCV to find best hyperparameters\n",
    "model = Ridge(random_state=1)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': uniform(0, 10),\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(model, param_grid, n_iter=20, scoring='neg_mean_absolute_error', n_jobs=-1, cv=5, random_state=1)\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)\n",
    "print(search.best_estimator_)\n",
    "best_param = search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.193325587528965\n"
     ]
    }
   ],
   "source": [
    "# test on validation set\n",
    "model = Ridge(**best_param, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation training\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = Ridge(alpha=best_param['alpha'], solver=best_param['solver'], random_state=1)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

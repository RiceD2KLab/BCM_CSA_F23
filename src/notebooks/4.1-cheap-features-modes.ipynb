{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# user defined methods\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from modeling import split_data, train_model\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../../models/cheap_features/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models: Finding cheap features to predict Central Sleep Apnea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_loc = '../../data/processed/cheap_features/'\n",
    "datasets = os.listdir('../../data/processed/cheap_features/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ahi_c0h4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [20:17<00:00,  9.59s/it]\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "model_name = None\n",
    "best_mae = 100000\n",
    "best_dataset = None\n",
    "\n",
    "for dataset in tqdm(datasets):\n",
    "    # Load data\n",
    "    df = pd.read_csv(folder_loc + dataset)\n",
    "\n",
    "    features = df.columns.tolist()\n",
    "    features.remove(target)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)\n",
    "\n",
    "    # Train xgboost\n",
    "\n",
    "    mae_xgb, model_xgb = train_model(XGBRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train random forest\n",
    "\n",
    "    mae_rf, model_rf = train_model(RandomForestRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train linear regression\n",
    "\n",
    "    mae_lr, model_lr = train_model(LinearRegression(), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train lasso\n",
    "\n",
    "    mae_lasso, model_lasso = train_model(Lasso(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train ridge\n",
    "\n",
    "    mae_ridge, model_ridge = train_model(Ridge(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train decision tree\n",
    "\n",
    "    mae_dt, model_dt = train_model(DecisionTreeRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Save best model\n",
    "\n",
    "    if mae_xgb < best_mae:\n",
    "        best_mae = mae_xgb\n",
    "        best_model = model_xgb\n",
    "        model_name = 'xgb'\n",
    "        best_dataset = dataset\n",
    "    if mae_rf < best_mae:\n",
    "        best_mae = mae_rf\n",
    "        best_model = model_rf\n",
    "        model_name = 'rf'\n",
    "        best_dataset = dataset\n",
    "    if mae_lr < best_mae:\n",
    "        best_mae = mae_lr\n",
    "        best_model = model_lr\n",
    "        model_name = 'lr'\n",
    "        best_dataset = dataset\n",
    "    if mae_lasso < best_mae:\n",
    "        best_mae = mae_lasso\n",
    "        best_model = model_lasso\n",
    "        model_name = 'lasso'\n",
    "        best_dataset = dataset\n",
    "    if mae_ridge < best_mae:\n",
    "        best_mae = mae_ridge\n",
    "        best_model = model_ridge\n",
    "        model_name = 'ridge'\n",
    "        best_dataset = dataset\n",
    "    if mae_dt < best_mae:\n",
    "        best_mae = mae_dt\n",
    "        best_model = model_dt\n",
    "        model_name = 'dt'\n",
    "        best_dataset = dataset\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "pickle.dump(best_model, open('../../models/cheap_features/' + model_name + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge 4.635646174021972\n"
     ]
    }
   ],
   "source": [
    "print(model_name, best_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hip', 'neck20', 'coffee15', 'tea15', 'soda15', 'evsmok15',\n",
       "       'smknow15', 'asa15', 'smokstat_s1', 'bmi_s1', 'weight', 'waist',\n",
       "       'height', 'weight20', 'nsrrid'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = pd.read_csv('../../data/interim/shhs-data-dictionary-0.20.0-variables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the rows where id == best_model.feature_names_in_\n",
    "features_dict = features_dict[features_dict['id'].isin(best_model.feature_names_in_)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict[['display_name', 'description', 'folder']].to_csv('./results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antropometric features and Lifestyle and Behavioural features are the most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and model\n",
    "import pickle\n",
    "\n",
    "best_model = pickle.load(open('../../models/cheap_features/ridge.pkl', 'rb'))\n",
    "df = pd.read_csv('../../data/processed/cheap_features/Ant_Lif.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns.tolist()\n",
    "features.remove(target)\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 4.434528937795567, 'solver': 'sparse_cg'}\n",
      "-4.723208539258343\n",
      "Ridge(alpha=4.434528937795567, random_state=1, solver='sparse_cg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# do RandomizedSearchCV to find best hyperparameters\n",
    "model = Ridge(random_state=1)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': uniform(0, 10),\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(model, param_grid, n_iter=20, scoring='neg_mean_absolute_error', n_jobs=-1, cv=5, random_state=1)\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)\n",
    "print(search.best_estimator_)\n",
    "best_param = search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.625547550719264\n",
      "4.569842143977\n"
     ]
    }
   ],
   "source": [
    "# test on validation set\n",
    "model = Ridge(**best_param, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, model.predict(X_test))\n",
    "print(mae)\n",
    "print(mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.75856807 -4.8232436  -4.75379321 -4.76452204 -4.51591528]\n",
      "-4.7232084399072125\n"
     ]
    }
   ],
   "source": [
    "# cross validation training\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = Ridge(alpha=best_param['alpha'], solver=best_param['solver'], random_state=1)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = os.listdir('../../data/interim/feature_selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [dataset for dataset in datasets if 'ahi_c0h4a' in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_loc = '../../data/interim/feature_selection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ahi_c0h4a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:34<00:00, 15.78s/it]\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "model_name = None\n",
    "best_mae = 100000\n",
    "best_dataset = None\n",
    "\n",
    "for dataset in tqdm(datasets):\n",
    "    # Load data\n",
    "    df = pd.read_csv(folder_loc + dataset)\n",
    "\n",
    "    features = df.columns.tolist()\n",
    "    features.remove(target)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)\n",
    "\n",
    "    # Train xgboost\n",
    "\n",
    "    mae_xgb, model_xgb = train_model(XGBRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train random forest\n",
    "\n",
    "    mae_rf, model_rf = train_model(RandomForestRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train linear regression\n",
    "\n",
    "    mae_lr, model_lr = train_model(LinearRegression(), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train lasso\n",
    "\n",
    "    mae_lasso, model_lasso = train_model(Lasso(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train ridge\n",
    "\n",
    "    mae_ridge, model_ridge = train_model(Ridge(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train decision tree\n",
    "\n",
    "    mae_dt, model_dt = train_model(DecisionTreeRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Save best model\n",
    "\n",
    "    if mae_xgb < best_mae:\n",
    "        best_mae = mae_xgb\n",
    "        best_model = model_xgb\n",
    "        model_name = 'xgb'\n",
    "        best_dataset = dataset\n",
    "    if mae_rf < best_mae:\n",
    "        best_mae = mae_rf\n",
    "        best_model = model_rf\n",
    "        model_name = 'rf'\n",
    "        best_dataset = dataset\n",
    "    if mae_lr < best_mae:\n",
    "        best_mae = mae_lr\n",
    "        best_model = model_lr\n",
    "        model_name = 'lr'\n",
    "        best_dataset = dataset\n",
    "    if mae_lasso < best_mae:\n",
    "        best_mae = mae_lasso\n",
    "        best_model = model_lasso\n",
    "        model_name = 'lasso'\n",
    "        best_dataset = dataset\n",
    "    if mae_ridge < best_mae:\n",
    "        best_mae = mae_ridge\n",
    "        best_model = model_ridge\n",
    "        model_name = 'ridge'\n",
    "        best_dataset = dataset\n",
    "    if mae_dt < best_mae:\n",
    "        best_mae = mae_dt\n",
    "        best_model = model_dt\n",
    "        model_name = 'dt'\n",
    "        best_dataset = dataset\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "pickle.dump(best_model, open('../../models/cheap_features/' + model_name + '_feature_selection.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forward_selection_ahi_c0h4a_AIC.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'../../data/interim/feature_selection/{best_dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns.tolist()\n",
    "features.remove(target)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge 5.815896127964164\n"
     ]
    }
   ],
   "source": [
    "print(model_name, best_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best feature selection method is forward selection but the results are not as good as our simple feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and model\n",
    "import pickle\n",
    "\n",
    "best_model = pickle.load(open('../../models/cheap_features/ridge_feature_selection.pkl', 'rb'))\n",
    "df = pd.read_csv('../../data/processed/cheap_features/Ant_Lif.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ahi_c0h4a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ahi_c0h4a'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/jingwenhu/Documents/GitHub/BCM_CSA_F23/src/notebooks/4.1-cheap-features-modes.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jingwenhu/Documents/GitHub/BCM_CSA_F23/src/notebooks/4.1-cheap-features-modes.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_train, X_test, y_train, y_test, X_val, y_val \u001b[39m=\u001b[39m split_data(df, features, target)\n",
      "File \u001b[0;32m~/Documents/GitHub/BCM_CSA_F23/src/notebooks/../utils/modeling.py:16\u001b[0m, in \u001b[0;36msplit_data\u001b[0;34m(data, features, target)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m     14\u001b[0m \u001b[39m# Split on test/train 80/20\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# split startified on target\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(data[features], data[target], test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[39m# make validation set\u001b[39;00m\n\u001b[1;32m     18\u001b[0m X_train, X_val, y_train, y_val \u001b[39m=\u001b[39m train_test_split(X_train, y_train, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ahi_c0h4a'"
     ]
    }
   ],
   "source": [
    "features = df.columns.tolist()\n",
    "features.remove(target)\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8025788737668\n",
      "5.853749233904157\n"
     ]
    }
   ],
   "source": [
    "# test on validation set\n",
    "model = Ridge(**best_param, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, model.predict(X_test))\n",
    "print(mae)\n",
    "print(mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.02496851 -6.04835237 -5.84749582 -5.9696119  -5.75898685]\n",
      "-5.92988309020622\n"
     ]
    }
   ],
   "source": [
    "# cross validation training\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = Ridge(alpha=best_param['alpha'], solver=best_param['solver'], random_state=1)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# user defined methods\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from modeling import split_data, train_model\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../../models/cheap_features/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models: Finding cheap features to predict Central Sleep Apnea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_loc = '../../data/processed/cheap_features/'\n",
    "datasets = os.listdir('../../data/processed/cheap_features/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ahi_c0h4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/127 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/127 [00:17<18:02,  8.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jingwenhu/Documents/GitHub/BCM_CSA_F23/src/notebooks/4.1-cheap-features-modes.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jingwenhu/Documents/GitHub/BCM_CSA_F23/src/notebooks/4.1-cheap-features-modes.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m mae_xgb, model_xgb \u001b[39m=\u001b[39m train_model(XGBRegressor(random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), X_train, y_train, X_test, y_test, X_val, y_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jingwenhu/Documents/GitHub/BCM_CSA_F23/src/notebooks/4.1-cheap-features-modes.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Train random forest\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jingwenhu/Documents/GitHub/BCM_CSA_F23/src/notebooks/4.1-cheap-features-modes.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m mae_rf, model_rf \u001b[39m=\u001b[39m train_model(RandomForestRegressor(random_state\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), X_train, y_train, X_test, y_test, X_val, y_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jingwenhu/Documents/GitHub/BCM_CSA_F23/src/notebooks/4.1-cheap-features-modes.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Train linear regression\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jingwenhu/Documents/GitHub/BCM_CSA_F23/src/notebooks/4.1-cheap-features-modes.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m mae_lr, model_lr \u001b[39m=\u001b[39m train_model(LinearRegression(), X_train, y_train, X_test, y_test, X_val, y_val)\n",
      "File \u001b[0;32m~/Documents/GitHub/BCM_CSA_F23/src/notebooks/../utils/modeling.py:38\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, X_train, y_train, X_test, y_test, X_val, y_val)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Train model and return predictions.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m    tuple: mae, model\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_absolute_error\n\u001b[0;32m---> 38\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     39\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_val)\n\u001b[1;32m     40\u001b[0m \u001b[39m# Evaluaate\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    460\u001b[0m )(\n\u001b[1;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    462\u001b[0m         t,\n\u001b[1;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    464\u001b[0m         X,\n\u001b[1;32m    465\u001b[0m         y,\n\u001b[1;32m    466\u001b[0m         sample_weight,\n\u001b[1;32m    467\u001b[0m         i,\n\u001b[1;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    472\u001b[0m     )\n\u001b[1;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/tree/_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1292\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m   1321\u001b[0m         X,\n\u001b[1;32m   1322\u001b[0m         y,\n\u001b[1;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1325\u001b[0m     )\n\u001b[1;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "model_name = None\n",
    "best_mae = 100000\n",
    "best_dataset = None\n",
    "\n",
    "for dataset in tqdm(datasets):\n",
    "    # Load data\n",
    "    df = pd.read_csv(folder_loc + dataset)\n",
    "\n",
    "    features = df.columns.tolist()\n",
    "    features.remove(target)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)\n",
    "\n",
    "    # Train xgboost\n",
    "\n",
    "    mae_xgb, model_xgb = train_model(XGBRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train random forest\n",
    "\n",
    "    mae_rf, model_rf = train_model(RandomForestRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train linear regression\n",
    "\n",
    "    mae_lr, model_lr = train_model(LinearRegression(), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train lasso\n",
    "\n",
    "    mae_lasso, model_lasso = train_model(Lasso(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train ridge\n",
    "\n",
    "    mae_ridge, model_ridge = train_model(Ridge(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train decision tree\n",
    "\n",
    "    mae_dt, model_dt = train_model(DecisionTreeRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Save best model\n",
    "\n",
    "    if mae_xgb < best_mae:\n",
    "        best_mae = mae_xgb\n",
    "        best_model = model_xgb\n",
    "        model_name = 'xgb'\n",
    "        best_dataset = dataset\n",
    "    if mae_rf < best_mae:\n",
    "        best_mae = mae_rf\n",
    "        best_model = model_rf\n",
    "        model_name = 'rf'\n",
    "        best_dataset = dataset\n",
    "    if mae_lr < best_mae:\n",
    "        best_mae = mae_lr\n",
    "        best_model = model_lr\n",
    "        model_name = 'lr'\n",
    "        best_dataset = dataset\n",
    "    if mae_lasso < best_mae:\n",
    "        best_mae = mae_lasso\n",
    "        best_model = model_lasso\n",
    "        model_name = 'lasso'\n",
    "        best_dataset = dataset\n",
    "    if mae_ridge < best_mae:\n",
    "        best_mae = mae_ridge\n",
    "        best_model = model_ridge\n",
    "        model_name = 'ridge'\n",
    "        best_dataset = dataset\n",
    "    if mae_dt < best_mae:\n",
    "        best_mae = mae_dt\n",
    "        best_model = model_dt\n",
    "        model_name = 'dt'\n",
    "        best_dataset = dataset\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "pickle.dump(best_model, open('../../models/cheap_features/' + model_name + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge 4.635646174021972\n"
     ]
    }
   ],
   "source": [
    "print(model_name, best_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hip', 'neck20', 'coffee15', 'tea15', 'soda15', 'evsmok15',\n",
       "       'smknow15', 'asa15', 'smokstat_s1', 'bmi_s1', 'weight', 'waist',\n",
       "       'height', 'weight20', 'nsrrid'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = pd.read_csv('../../data/interim/shhs-data-dictionary-0.20.0-variables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the rows where id == best_model.feature_names_in_\n",
    "features_dict = features_dict[features_dict['id'].isin(best_model.feature_names_in_)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict[['display_name', 'description', 'folder']].to_csv('./results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antropometric features and Lifestyle and Behavioural features are the most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and model\n",
    "import pickle\n",
    "\n",
    "best_model = pickle.load(open('../../models/cheap_features/ridge.pkl', 'rb'))\n",
    "df = pd.read_csv('../../data/processed/cheap_features/Ant_Lif.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns.tolist()\n",
    "features.remove(target)\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 4.434528937795567, 'solver': 'sparse_cg'}\n",
      "-4.723208539258343\n",
      "Ridge(alpha=4.434528937795567, random_state=1, solver='sparse_cg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/jingwenhu/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# do RandomizedSearchCV to find best hyperparameters\n",
    "model = Ridge(random_state=1)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': uniform(0, 10),\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(model, param_grid, n_iter=20, scoring='neg_mean_absolute_error', n_jobs=-1, cv=5, random_state=1)\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)\n",
    "print(search.best_estimator_)\n",
    "best_param = search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.625547550719264\n",
      "4.569842143977\n"
     ]
    }
   ],
   "source": [
    "# test on validation set\n",
    "model = Ridge(**best_param, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, model.predict(X_test))\n",
    "print(mae)\n",
    "print(mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.75856807 -4.8232436  -4.75379321 -4.76452204 -4.51591528]\n",
      "-4.7232084399072125\n"
     ]
    }
   ],
   "source": [
    "# cross validation training\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = Ridge(alpha=best_param['alpha'], solver=best_param['solver'], random_state=1)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = os.listdir('../../data/interim/feature_selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['decision_tree_ahi_c0h4a.csv', 'mi_ahi_c0h4a.csv', 'random_forest_ahi_c0h4a.csv', 'forward_selection_ahi_c0h4a_AIC.csv', 'forward_selection_ahi_c0h4a.csv', 'backward_selection_ahi_c0h4a.csv']\n"
     ]
    }
   ],
   "source": [
    "datasets = [dataset for dataset in datasets if 'ahi_c0h4a' in dataset]\n",
    "\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_loc = '../../data/interim/feature_selection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ahi_c0h4a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree_ahi_c0h4a.csv ['nsrrid', 'pptid', 'ecgdate', 'lvh3_1', 'lvh3_3', 'st4_1_3', 'st5_1_3', 'lvhst', 'lbbb', 'rbbb', 'ilbbb', 'irbbb', 'lah', 'iventblk', 'antsepmi', 'infmi', 'nonsp_st', 'nonsp_tw', 'ventrate', 'qrs', 'apbs', 'vpbs', 'truposmi', 'gender', 'race', 'mstat', 'srhype', 'parrptdiab', 'cgpkyr', 'alcoh', 'systbp', 'diasbp', 'hip', 'chol', 'hdl', 'trig', 'fev1', 'fvc', 'aai', 'ankbp', 'armbp', 'imdbpae', 'ursbpae', 'urdbpae', 'skrctnae', 'syst120', 'dias120', 'syst220', 'dias220', 'syst320', 'dias320', 'neck20', 'angina15', 'mi15', 'stroke15', 'hf15', 'cabg15', 'ca15', 'othrcs15', 'sa15', 'emphys15', 'crbron15', 'copd15', 'asthma15', 'asth1215', 'cough315', 'phlegm15', 'runny15', 'sinus15', 'coffee15', 'tea15', 'soda15', 'evsmok15', 'ns1yr15', 'yrsns15', 'smknow15', 'cigday15', 'avesmk15', 'wine15', 'beer15', 'shots15', 'asa15', 'asalw15', 'slpill15', 'nitro15', 'napshr15', 'napsmn15', 'stress15', 'estrgn1', 'progst1', 'htnmed1', 'anar1a1', 'lipid1', 'ohga1', 'insuln1', 'sympth1', 'tca1', 'asa1', 'nsaid1', 'benzod1', 'premar1', 'pdei1', 'ntca1', 'warf1', 'loop1', 'hctz1', 'hctzk1', 'ccbir1', 'ccbsr1', 'alpha1', 'basq1', 'thry1', 'istrd1', 'ostrd1', 'beta1', 'ccb1', 'ace1', 'aced1', 'diuret1', 'dig1', 'ntg1', 'genhth25', 'cmp1yr25', 'vigact25', 'modact25', 'lift25', 'climbs25', 'climb125', 'bend25', 'wk1ml25', 'wksblk25', 'wk1blk25', 'bathe25', 'phctdn25', 'phacls25', 'limit25', 'exefrt25', 'emctdn25', 'emacls25', 'carful25', 'probsa25', 'bdpain25', 'painin25', 'pep25', 'nrvous25', 'down25', 'calm25', 'energ25', 'blue25', 'worn25', 'happy25', 'tired25', 'hlthlm25', 'sickez25', 'hlthy25', 'worse25', 'exclnt25', 'tfawdh02', 'tfawdm02', 'tfawda02', 'tfaweh02', 'tfawem02', 'tfawea02', 'mi2slp02', 'twuwdh02', 'twuwdm02', 'twuwda02', 'twuweh02', 'twuwem02', 'twuwea02', 'hrswd02', 'hrswe02', 'naps02', 'tfa02', 'wudnrs02', 'wu2em02', 'funres02', 'sleepy02', 'tkpill02', 'nges02', 'hvsnrd02', 'hosnr02', 'loudsn02', 'yrssnr02', 'issnor02', 'surgtr02', 'stpbrt02', 'hostbr02', 'mdsa02', 'cpap02', 'surgsa02', 'cough02', 'cp02', 'sob02', 'sweats02', 'noise02', 'painjt02', 'hb02', 'legcrp02', 'needbr02', 'membhh02', 'sitrd02', 'watv02', 'sitpub02', 'pgrcar02', 'lydwn02', 'sittlk02', 'sitlch02', 'incar02', 'attabl02', 'drive02', 'prev_hx_mi', 'prev_hx_stroke', 'rawpf_s1', 'pf_s1', 'rawrp_s1', 'rp_s1', 'rawbp_s1', 'bp_s1', 'rawgh_s1', 'gh_s1', 'rawvt_s1', 'vt_s1', 'rawsf_s1', 'sf_s1', 'rawre_s1', 're_s1', 'rawmh_s1', 'mh_s1', 'pcs_s1', 'mcs_s1', 'age_s1', 'smokstat_s1', 'htnderv_s1', 'ess_s1', 'shhs1_ae', 'shhs1_cf', 'shhs1_hi', 'shhs1_sh', 'shhs1_ms', 'shhs1_ql', 'shhs1_tcvd', 'shhs1_all', 'ethnicity', 'bmi_s1', 'educat', 'date02', 'date25', 'weight', 'waist', 'height', 'weight20', 'lang15', 'age_category_s1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:22<01:50, 22.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.819445065906095\n",
      "mi_ahi_c0h4a.csv ['av1deg', 'lbbb', 'rbbb', 'antsepmi', 'rtrial', 'rvh', 'qrs', 'afib', 'paced', 'apbs', 'vpbs', 'truposmi', 'gender', 'race', 'mstat', 'srhype', 'parrptdiab', 'cgpkyr', 'alcoh', 'systbp', 'hip', 'hdl', 'trig', 'fev1', 'fvc', 'armbp', 'ecg', 'imlohrae', 'urdbpae', 'skrctnae', 'tripae', 'othprbae', 'syst120', 'dias120', 'syst220', 'syst320', 'neck20', 'angina15', 'mi15', 'stroke15', 'hf15', 'cabg15', 'othrcs15', 'pacem15', 'sa15', 'emphys15', 'copd15', 'asthma15', 'asth1215', 'cough315', 'phlegm15', 'sinus15', 'coffee15', 'tea15', 'ns1yr15', 'yrsns15', 'smknow15', 'cigday15', 'avesmk15', 'wine15', 'beer15', 'asa15', 'asalw15', 'slpill15', 'nitro15', 'napsmn15', 'estrgn1', 'progst1', 'htnmed1', 'lipid1', 'ohga1', 'insuln1', 'sympth1', 'asa1', 'nsaid1', 'benzod1', 'premar1', 'pdei1', 'ntca1', 'warf1', 'loop1', 'hctz1', 'ccbsr1', 'alpha1', 'alphad1', 'anar1c1', 'anar31', 'pvdl1', 'niac1', 'thry1', 'betad1', 'ccb1', 'aced1', 'diuret1', 'ntg1', 'modact25', 'climbs25', 'climb125', 'bend25', 'wk1ml25', 'wksblk25', 'wk1blk25', 'phctdn25', 'phacls25', 'limit25', 'carful25', 'bdpain25', 'painin25', 'pep25', 'nrvous25', 'down25', 'energ25', 'blue25', 'worn25', 'happy25', 'hlthlm25', 'sickez25', 'hlthy25', 'exclnt25', 'tfawdh02', 'tfawdm02', 'tfaweh02', 'tfawem02', 'tfawea02', 'mi2slp02', 'twuweh02', 'twuwem02', 'hrswd02', 'hrswe02', 'naps02', 'tfa02', 'wudnrs02', 'wu2em02', 'sleepy02', 'tkpill02', 'hvsnrd02', 'hosnr02', 'loudsn02', 'issnor02', 'surgtr02', 'stpbrt02', 'hostbr02', 'mdsa02', 'cough02', 'sob02', 'sweats02', 'noise02', 'needbr02', 'membhh02', 'sitrd02', 'sitpub02', 'pgrcar02', 'lydwn02', 'sittlk02', 'sitlch02', 'incar02', 'drive02', 'prev_hx_stroke', 'rawpf_s1', 'pf_s1', 'rawbp_s1', 'bp_s1', 'rawgh_s1', 'gh_s1', 'rawvt_s1', 'vt_s1', 'rawsf_s1', 'sf_s1', 'rawre_s1', 'mh_s1', 'pcs_s1', 'mcs_s1', 'age_s1', 'smokstat_s1', 'htnderv_s1', 'ess_s1', 'shhs1_ae', 'shhs1_cf', 'shhs1_sh', 'shhs1_ql', 'shhs1_avars', 'shhs1_tcvd', 'shhs1_all', 'ethnicity', 'bmi_s1', 'date02', 'date25', 'weight', 'waist', 'height', 'weight20', 'lang15', 'age_category_s1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:37<01:12, 18.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.819445065906095\n",
      "random_forest_ahi_c0h4a.csv ['nsrrid', 'pptid', 'ecgdate', 'lvh3_1', 'lvh3_3', 'st4_1_3', 'st5_1_3', 'lvhst', 'lbbb', 'rbbb', 'ilbbb', 'irbbb', 'lah', 'iventblk', 'antsepmi', 'infmi', 'nonsp_st', 'nonsp_tw', 'ventrate', 'qrs', 'apbs', 'vpbs', 'truposmi', 'gender', 'race', 'mstat', 'srhype', 'parrptdiab', 'cgpkyr', 'alcoh', 'systbp', 'diasbp', 'hip', 'chol', 'hdl', 'trig', 'fev1', 'fvc', 'aai', 'ankbp', 'armbp', 'imdbpae', 'ursbpae', 'urdbpae', 'skrctnae', 'syst120', 'dias120', 'syst220', 'dias220', 'syst320', 'dias320', 'neck20', 'angina15', 'mi15', 'stroke15', 'hf15', 'cabg15', 'ca15', 'othrcs15', 'sa15', 'emphys15', 'crbron15', 'copd15', 'asthma15', 'asth1215', 'cough315', 'phlegm15', 'runny15', 'sinus15', 'coffee15', 'tea15', 'soda15', 'evsmok15', 'ns1yr15', 'yrsns15', 'smknow15', 'cigday15', 'avesmk15', 'wine15', 'beer15', 'shots15', 'asa15', 'asalw15', 'slpill15', 'nitro15', 'napshr15', 'napsmn15', 'stress15', 'estrgn1', 'progst1', 'htnmed1', 'anar1a1', 'lipid1', 'ohga1', 'insuln1', 'sympth1', 'tca1', 'asa1', 'nsaid1', 'benzod1', 'premar1', 'pdei1', 'ntca1', 'warf1', 'loop1', 'hctz1', 'hctzk1', 'ccbir1', 'ccbsr1', 'alpha1', 'basq1', 'thry1', 'istrd1', 'ostrd1', 'beta1', 'ccb1', 'ace1', 'aced1', 'diuret1', 'dig1', 'ntg1', 'genhth25', 'cmp1yr25', 'vigact25', 'modact25', 'lift25', 'climbs25', 'climb125', 'bend25', 'wk1ml25', 'wksblk25', 'wk1blk25', 'bathe25', 'phctdn25', 'phacls25', 'limit25', 'exefrt25', 'emctdn25', 'emacls25', 'carful25', 'probsa25', 'bdpain25', 'painin25', 'pep25', 'nrvous25', 'down25', 'calm25', 'energ25', 'blue25', 'worn25', 'happy25', 'tired25', 'hlthlm25', 'sickez25', 'hlthy25', 'worse25', 'exclnt25', 'tfawdh02', 'tfawdm02', 'tfawda02', 'tfaweh02', 'tfawem02', 'tfawea02', 'mi2slp02', 'twuwdh02', 'twuwdm02', 'twuwda02', 'twuweh02', 'twuwem02', 'twuwea02', 'hrswd02', 'hrswe02', 'naps02', 'tfa02', 'wudnrs02', 'wu2em02', 'funres02', 'sleepy02', 'tkpill02', 'nges02', 'hvsnrd02', 'hosnr02', 'loudsn02', 'yrssnr02', 'issnor02', 'surgtr02', 'stpbrt02', 'hostbr02', 'mdsa02', 'cpap02', 'surgsa02', 'cough02', 'cp02', 'sob02', 'sweats02', 'noise02', 'painjt02', 'hb02', 'legcrp02', 'needbr02', 'membhh02', 'sitrd02', 'watv02', 'sitpub02', 'pgrcar02', 'lydwn02', 'sittlk02', 'sitlch02', 'incar02', 'attabl02', 'drive02', 'prev_hx_mi', 'prev_hx_stroke', 'rawpf_s1', 'pf_s1', 'rawrp_s1', 'rp_s1', 'rawbp_s1', 'bp_s1', 'rawgh_s1', 'gh_s1', 'rawvt_s1', 'vt_s1', 'rawsf_s1', 'sf_s1', 'rawre_s1', 're_s1', 'rawmh_s1', 'mh_s1', 'pcs_s1', 'mcs_s1', 'age_s1', 'smokstat_s1', 'htnderv_s1', 'ess_s1', 'shhs1_ae', 'shhs1_cf', 'shhs1_hi', 'shhs1_sh', 'shhs1_ms', 'shhs1_ql', 'shhs1_tcvd', 'shhs1_all', 'ethnicity', 'bmi_s1', 'educat', 'date02', 'date25', 'weight', 'waist', 'height', 'weight20', 'lang15', 'age_category_s1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:59<00:59, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.819445065906095\n",
      "forward_selection_ahi_c0h4a_AIC.csv ['neck20', 'bmi_s1', 'age_s1', 'gender', 'diasbp', 'funres02', 'shhs1_tcvd', 'ess_s1', 'nonsp_st', 'hosnr02', 'benzod1', 'ccb1', 'nsrrid', 'shhs1_qc', 'twuweh02', 'race', 'estrgn1', 'waist', 'soda15', 'tea15', 'urdbpae', 'diuret1', 'pvdl1', 'height', 'weight', 'systbp', 'hvsnrd02', 'ntca1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [01:02<00:26, 13.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7830904622074595\n",
      "forward_selection_ahi_c0h4a.csv ['neck20', 'weight', 'age_s1', 'rawvt_s1', 'diasbp', 'asalw15', 'shhs1_tcvd', 'pptid', 'nonsp_st', 'twuweh02', 'ccb1', 'sleepy02', 'hf15', 'smknow15', 'hosnr02', 'shhs1_qc', 'tfawem02', 'systbp', 'vt_s1', 'hctz1', 'aai', 'drive02', 'race', 'ethnicity', 'soda15', 'napshr15', 'othrcs15', 'afib', 'warf1', 'phctdn25', 'phlegm15', 'carful25', 'shhs1_all', 'shhs1_ae', 'nsaid1', 'aced1', 'truposmi', 'exclnt25', 'wk1ml25', 'phacls25', 'trig', 'shots15', 'irbbb', 'issnor02', 'basq1', 'asthma15', 'copd15', 'ace1', 'hostbr02', 'cp02', 'sweats02', 'ventrate', 'av1deg', 'height', 'gender', 'tfawda02', 'mi2slp02', 'evsmok15', 'funres02', 'urdbpae', 'tfaweh02', 'runny15', 'pvdl1', 'tea15', 'bend25', 'bathe25', 'tripae', 'hip', 'waist', 'shhs1_ql', 'slpill15', 'ccbir1', 'st5_1_3', 'nonsp_tw', 'nsrrid', 'cigday15', 'pdei1', 'dig1', 'ntca1', 'stress15', 'mob1', 'sickez25', 'worse25', 'shhs1_ms', 'nitro15', 'wine15', 'cough315', 'smokstat_s1', 'ecg', 'lipid1', 'niac1', 'crbron15', 'tfawea02', 'shhs1_hi', 'date02', 'coffee15', 'lah', 'mi15', 'paced', 'emphys15', 'twuwda02', 'cgpkyr', 'avesmk15', 'mdsa02', 'hctzk1', 'painjt02', 'bdpain25']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:10<00:11, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7830904622074595\n",
      "backward_selection_ahi_c0h4a.csv ['nsrrid', 'pptid', 'ecgdate', 'lvh3_1', 'lvh3_3', 'st4_1_3', 'st5_1_3', 'lvhst', 'mob1', 'part2deg', 'mob2', 'av1deg', 'lbbb', 'rbbb', 'ilbbb', 'irbbb', 'lah', 'iventblk', 'antsepmi', 'infmi', 'antlatmi', 'nonsp_st', 'nonsp_tw', 'rtrial', 'rvh', 'ventrate', 'qrs', 'afib', 'paced', 'nodal', 'apbs', 'truposmi', 'gender', 'race', 'mstat', 'cgpkyr', 'systbp', 'diasbp', 'hip', 'hdl', 'trig', 'fvc', 'aai', 'armbp', 'ecg', 'imsbpae', 'imdbpae', 'imosatae', 'imhihrae', 'imlohrae', 'ursbpae', 'urdbpae', 'urosatae', 'skrctnae', 'tripae', 'othprbae', 'syst120', 'dias120', 'syst220', 'dias220', 'syst320', 'neck20', 'angina15', 'mi15', 'stroke15', 'hf15', 'othrcs15', 'pacem15', 'emphys15', 'crbron15', 'copd15', 'asthma15', 'asth1215', 'cough315', 'phlegm15', 'runny15', 'coffee15', 'tea15', 'soda15', 'evsmok15', 'yrsns15', 'smknow15', 'avesmk15', 'wine15', 'asa15', 'asalw15', 'slpill15', 'nitro15', 'napshr15', 'stress15', 'progst1', 'htnmed1', 'lipid1', 'ohga1', 'insuln1', 'sympth1', 'asa1', 'nsaid1', 'benzod1', 'pdei1', 'ntca1', 'warf1', 'loop1', 'hctz1', 'hctzk1', 'ccbir1', 'ccbsr1', 'alpha1', 'alphad1', 'anar1b1', 'anar1c1', 'anar31', 'pvdl1', 'basq1', 'niac1', 'istrd1', 'ostrd1', 'beta1', 'betad1', 'ccb1', 'ace1', 'aced1', 'vaso1', 'vasod1', 'diuret1', 'dig1', 'genhth25', 'cmp1yr25', 'vigact25', 'lift25', 'climbs25', 'climb125', 'bend25', 'wk1ml25', 'wksblk25', 'wk1blk25', 'bathe25', 'phctdn25', 'phacls25', 'limit25', 'exefrt25', 'emctdn25', 'emacls25', 'carful25', 'probsa25', 'bdpain25', 'painin25', 'pep25', 'nrvous25', 'calm25', 'energ25', 'blue25', 'worn25', 'happy25', 'tired25', 'hlthlm25', 'sickez25', 'hlthy25', 'worse25', 'exclnt25', 'tfawdh02', 'tfawdm02', 'tfawda02', 'tfaweh02', 'tfawem02', 'tfawea02', 'mi2slp02', 'twuwdh02', 'twuwdm02', 'twuwda02', 'twuweh02', 'twuwem02', 'hrswd02', 'hrswe02', 'tfa02', 'wudnrs02', 'wu2em02', 'funres02', 'sleepy02', 'tkpill02', 'hosnr02', 'loudsn02', 'issnor02', 'surgtr02', 'stpbrt02', 'hostbr02', 'cough02', 'cp02', 'sob02', 'sweats02', 'painjt02', 'hb02', 'legcrp02', 'needbr02', 'membhh02', 'sitrd02', 'watv02', 'sitpub02', 'lydwn02', 'sittlk02', 'sitlch02', 'attabl02', 'drive02', 'prev_hx_mi', 'prev_hx_stroke', 'rawpf_s1', 'pf_s1', 'rawrp_s1', 'rp_s1', 'rawbp_s1', 'bp_s1', 'rawgh_s1', 'gh_s1', 'rawvt_s1', 'vt_s1', 'rawsf_s1', 'sf_s1', 'rawre_s1', 're_s1', 'rawmh_s1', 'pcs_s1', 'mcs_s1', 'age_s1', 'smokstat_s1', 'htnderv_s1', 'ess_s1', 'shhs1_ae', 'shhs1_bp', 'shhs1_cf', 'shhs1_hi', 'shhs1_sh', 'shhs1_ms', 'shhs1_qc', 'shhs1_ql', 'shhs1_meds', 'shhs1_psg', 'shhs1_avars', 'shhs1_tcvd', 'shhs1_all', 'ethnicity', 'educat', 'date02', 'weight', 'waist', 'height', 'lang15', 'age_category_s1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:38<00:00, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7830904622074595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "model_name = None\n",
    "best_mae = 100000\n",
    "best_dataset = None\n",
    "\n",
    "for dataset in tqdm(datasets):\n",
    "    # Load data\n",
    "    df = pd.read_csv(folder_loc + dataset)\n",
    "\n",
    "    features = df.columns.tolist()\n",
    "    features.remove(target)\n",
    "    print(dataset, features)\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)\n",
    "\n",
    "    # Train xgboost\n",
    "\n",
    "    mae_xgb, model_xgb = train_model(XGBRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train random forest\n",
    "\n",
    "    mae_rf, model_rf = train_model(RandomForestRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train linear regression\n",
    "\n",
    "    mae_lr, model_lr = train_model(LinearRegression(), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train lasso\n",
    "\n",
    "    mae_lasso, model_lasso = train_model(Lasso(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train ridge\n",
    "\n",
    "    mae_ridge, model_ridge = train_model(Ridge(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Train decision tree\n",
    "\n",
    "    mae_dt, model_dt = train_model(DecisionTreeRegressor(random_state=1), X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "    # Save best model\n",
    "\n",
    "    if mae_xgb < best_mae:\n",
    "        best_mae = mae_xgb\n",
    "        best_model = model_xgb\n",
    "        model_name = 'xgb'\n",
    "        best_dataset = dataset\n",
    "    if mae_rf < best_mae:\n",
    "        best_mae = mae_rf\n",
    "        best_model = model_rf\n",
    "        model_name = 'rf'\n",
    "        best_dataset = dataset\n",
    "    if mae_lr < best_mae:\n",
    "        best_mae = mae_lr\n",
    "        best_model = model_lr\n",
    "        model_name = 'lr'\n",
    "        best_dataset = dataset\n",
    "    if mae_lasso < best_mae:\n",
    "        best_mae = mae_lasso\n",
    "        best_model = model_lasso\n",
    "        model_name = 'lasso'\n",
    "        best_dataset = dataset\n",
    "    if mae_ridge < best_mae:\n",
    "        best_mae = mae_ridge\n",
    "        best_model = model_ridge\n",
    "        model_name = 'ridge'\n",
    "        best_dataset = dataset\n",
    "    if mae_dt < best_mae:\n",
    "        best_mae = mae_dt\n",
    "        best_model = model_dt\n",
    "        model_name = 'dt'\n",
    "        best_dataset = dataset\n",
    "    print(best_mae)\n",
    "# Save model\n",
    "import pickle\n",
    "pickle.dump(best_model, open('../../models/cheap_features/' + model_name + '_feature_selection.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forward_selection_ahi_c0h4a_AIC.csv'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'../../data/interim/feature_selection/{best_dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neck20', 'bmi_s1', 'age_s1', 'gender', 'diasbp', 'funres02', 'shhs1_tcvd', 'ess_s1', 'nonsp_st', 'hosnr02', 'benzod1', 'ccb1', 'nsrrid', 'shhs1_qc', 'twuweh02', 'race', 'estrgn1', 'waist', 'soda15', 'tea15', 'urdbpae', 'diuret1', 'pvdl1', 'height', 'weight', 'systbp', 'hvsnrd02', 'ntca1']\n"
     ]
    }
   ],
   "source": [
    "features = df.columns.tolist()\n",
    "features.remove(target)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge 5.7830904622074595\n"
     ]
    }
   ],
   "source": [
    "print(model_name, best_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best feature selection method is forward selection but the results are not as good as our simple feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and model\n",
    "import pickle\n",
    "\n",
    "best_model = pickle.load(open('../../models/cheap_features/ridge_feature_selection.pkl', 'rb'))\n",
    "df = pd.read_csv('../../data/processed/cheap_features/Ant_Lif.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ahi_c0h4a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ahi_c0h4a'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/jingwenhu/Documents/GitHub/BCM_CSA_F23/src/notebooks/4.1-cheap-features-modes.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jingwenhu/Documents/GitHub/BCM_CSA_F23/src/notebooks/4.1-cheap-features-modes.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_train, X_test, y_train, y_test, X_val, y_val \u001b[39m=\u001b[39m split_data(df, features, target)\n",
      "File \u001b[0;32m~/Documents/GitHub/BCM_CSA_F23/src/notebooks/../utils/modeling.py:16\u001b[0m, in \u001b[0;36msplit_data\u001b[0;34m(data, features, target)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m     14\u001b[0m \u001b[39m# Split on test/train 80/20\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# split startified on target\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(data[features], data[target], test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[39m# make validation set\u001b[39;00m\n\u001b[1;32m     18\u001b[0m X_train, X_val, y_train, y_val \u001b[39m=\u001b[39m train_test_split(X_train, y_train, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ahi_c0h4a'"
     ]
    }
   ],
   "source": [
    "features = df.columns.tolist()\n",
    "features.remove(target)\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = split_data(df, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8025788737668\n",
      "5.853749233904157\n"
     ]
    }
   ],
   "source": [
    "# test on validation set\n",
    "model = Ridge(**best_param, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, model.predict(X_test))\n",
    "print(mae)\n",
    "print(mae_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.02496851 -6.04835237 -5.84749582 -5.9696119  -5.75898685]\n",
      "-5.92988309020622\n"
     ]
    }
   ],
   "source": [
    "# cross validation training\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = Ridge(alpha=best_param['alpha'], solver=best_param['solver'], random_state=1)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
